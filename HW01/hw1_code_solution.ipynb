{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl_B9DrWuWUU"
      },
      "outputs": [],
      "source": [
        "!pip install mrjob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2MjrJDqt1yC",
        "outputId": "617ca2f7-9268-43ab-aba3-083e6ecf518f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting hw1_mrA_337604821_326922390.py\n"
          ]
        }
      ],
      "source": [
        "%%file hw1_mrA_337604821_326922390.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import re\n",
        "\n",
        "def split_properley (line):\n",
        "    item = line.split(',')\n",
        "    date = item[-3] # taking third item from the righ to left on the row, which represents the date\n",
        "    air_time = int(item[-2]) if item[-2].isnumeric() else 0 #getting the integer value fo the item second from the right side of the row\n",
        "\n",
        "    if item[2] != item[-4]:# checking if there are multiple genres or only 1.\n",
        "        genres = line.split('\\\"')[1].split(',') if item[0] != 'title' else \"Hello World\"\n",
        "    else:# There is only one genre for this tuple\n",
        "      genres = [item[2]]\n",
        "    title = item[0].strip()\n",
        "    return title, genres, air_time, date\n",
        "\n",
        "class MRWordFrequencyCount(MRJob):\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper,\n",
        "                   reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_count_genres),\n",
        "            #MRStep(reducer=self.reducer_max)\n",
        "        ]\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        title, genres, air_time, date = split_properley(line)# get relevant data from the tuple\n",
        "        try:\n",
        "            if 70000 <= int(air_time) < 90000 and re.search('[jqz]', title.lower()):# filter out by airtime and that title contains one of the letters j,q,z\n",
        "                for genre in genres:\n",
        "                    if genre.strip() in ['Sitcom', 'Talk', 'Politics', 'Spanish', 'Community', 'Martial arts']:\n",
        "                        ls = [title]\n",
        "                        ls.extend(genres)\n",
        "                        yield (tuple(ls), date)# if one of the genres is in the list then we will move this tuple reformatted to the next step\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    def reducer(self, key, dates):\n",
        "        yield key, len(set(dates))# reduce the value so it contains the number of unique dates\n",
        "\n",
        "    def reducer_count_genres(self, key, values):\n",
        "        total_dates = 0\n",
        "        for dates_count in values:\n",
        "            total_dates += dates_count\n",
        "        yield key, (total_dates, len(key)-1)# counting number of dates per key, counting number of genres\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRWordFrequencyCount.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmGa5-Hnue4k",
        "outputId": "0922a439-00c4-4c12-b478-8620a8b83482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/hw1_mrA_337604821_326922390.root.20240710.125931.013212\n",
            "Running step 1 of 2...\n",
            "Running step 2 of 2...\n",
            "job output is in /tmp/hw1_mrA_337604821_326922390.root.20240710.125931.013212/output\n",
            "Streaming final output from /tmp/hw1_mrA_337604821_326922390.root.20240710.125931.013212/output...\n",
            "[\"El Joven Ju\\u00e1rez\", \"Spanish\", \"Biography\"]\t[1, 2]\n",
            "[\"El Joven del Carrito\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"El Oreja Rajada\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"El Palenque\", \"Talk\"]\t[1, 1]\n",
            "[\"El Rediezcubrimiento de M\\u00e9xico\", \"Spanish\", \"Comedy-drama\"]\t[1, 2]\n",
            "[\"El Santos vs la Tetona Mendoza\", \"Spanish\", \"Comedy\", \"Animated\"]\t[1, 3]\n",
            "[\"El Santos vs. la T...a Mendoza\", \"Spanish\", \"Comedy\", \"Animated\"]\t[1, 3]\n",
            "[\"El Tejedor de Milagros\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"El Tigre de Guanajuato\", \"Spanish\", \"Adventure\"]\t[1, 2]\n",
            "[\"El Vizconde de Montecristo\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"El mejor\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Esos de P\\u00e9njamo\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Estrella Sin Luz\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Fallaste Coraz\\u00f3n\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Fashionably Late With Rachel Zoe\", \"Talk\", \"Fashion\"]\t[1, 2]\n",
            "[\"George Lopez\", \"Sitcom\"]\t[65, 1]\n",
            "[\"Hagit - Designer Jewelry\", \"Shopping\", \"Talk\"]\t[1, 2]\n",
            "[\"I Dream of Jeannie\", \"Sitcom\"]\t[21, 1]\n",
            "[\"Israel Tour June 2015\", \"Community\"]\t[5, 1]\n",
            "[\"Izrail' Plyus Predstavlyaet\", \"Community\"]\t[1, 1]\n",
            "[\"Jack Holt At The River\", \"Religious\", \"Community\"]\t[1, 2]\n",
            "[\"Jade Warrior\", \"Spanish\", \"Action\", \"Adventure\", \"Martial arts\"]\t[1, 4]\n",
            "[\"Jerry Springer\", \"Talk\"]\t[109, 1]\n",
            "[\"Jimmy Kimmel Live\", \"Talk\", \"Comedy\"]\t[9, 2]\n",
            "[\"Jonathan Last on The Dadly Virtues\", \"Special\", \"Talk\"]\t[1, 2]\n",
            "[\"Juan sin Miedo\", \"Spanish\", \"Drama\"]\t[2, 2]\n",
            "[\"Judo Budapest Grand Prix 2014 Highlights\", \"Special\", \"Sports non-event\", \"Martial arts\"]\t[1, 3]\n",
            "[\"Just Shoot Me\", \"Sitcom\"]\t[13, 1]\n",
            "[\"Justice With Judge Jeanine\", \"Talk\", \"News\"]\t[4, 2]\n",
            "[\"La Maldici\\u00f3n de la Momia Azteca\", \"Spanish\", \"Horror\"]\t[2, 2]\n",
            "[\"La Masacre de los P\\u00e9rez\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"La Monja Alf\\u00e9rez\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"La Oveja Negra\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"La Vida Dif\\u00edcil de una Mujer F\\u00e1cil\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"La visita que no toc\\u00f3 el timbre\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"Lamberto Quintero\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Late Night Joy\", \"Talk\"]\t[1, 1]\n",
            "[\"Lo Azul del Cielo\", \"Spanish\", \"Drama\", \"Romance\", \"Suspense\"]\t[1, 4]\n",
            "[\"Lo Mejor de Caso Cerrado\", \"Law\", \"Reality\", \"Talk\"]\t[1, 3]\n",
            "[\"Lo Mejor de la Madre Ang\\u00e9lica\", \"Talk\", \"Religious\"]\t[15, 2]\n",
            "[\"Los Campeones Justicieros\", \"Spanish\", \"Action\"]\t[1, 2]\n",
            "[\"Los Fern\\u00e1ndez de Peralvillo\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Los Hijos de Peralvillo\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Los Maistros: El D\\u00eda de la Santa Cruz\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"M\\u00e1s Vale P\\u00e1jaro en Mano\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"MediaBuzz\", \"News\", \"Talk\", \"Public affairs\", \"Politics\"]\t[2, 4]\n",
            "[\"Mejor Estar Solo\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"Mojados\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Mojoe\", \"Entertainment\", \"Talk\", \"Newsmagazine\"]\t[1, 3]\n",
            "[\"Music for Change: The Global Citizen\", \"Special\", \"Music\", \"Community\"]\t[1, 3]\n",
            "[\"Operaci\\u00f3n Jaque\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Programa do J\\u00f4\", \"Talk\", \"Interview\"]\t[12, 2]\n",
            "[\"Q & A\", \"News\", \"Talk\", \"Interview\"]\t[1, 3]\n",
            "[\"Q\", \"Talk\", \"Entertainment\", \"Variety\"]\t[2, 3]\n",
            "[\"Quadriga - The International Talk Show\", \"Talk\", \"Public affairs\", \"Newsmagazine\"]\t[1, 3]\n",
            "[\"Rosario Tijeras\", \"Spanish\", \"Crime drama\", \"Romance\"]\t[1, 3]\n",
            "[\"Santo y Mantequilla N\\u00e1poles\", \"Spanish\", \"Action\"]\t[1, 2]\n",
            "[\"Serpiente Azteca\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Soy el Hijo del Tah\\u00far\", \"Spanish\", \"Action\", \"Drama\"]\t[1, 3]\n",
            "[\"St. Joe Live Presents\", \"Community\"]\t[1, 1]\n",
            "[\"State of Mine: Jim Hunt Story\", \"Special\", \"Community\"]\t[1, 2]\n",
            "[\"The Daily Show With Jon Stewart\", \"Talk\", \"Interview\", \"Comedy\"]\t[11, 3]\n",
            "[\"The Dr. Oz Show\", \"Talk\", \"Health\"]\t[94, 2]\n",
            "[\"The Gossip Queens\", \"Talk\", \"Entertainment\"]\t[1, 2]\n",
            "[\"The Jamie Foxx Show\", \"Sitcom\"]\t[17, 1]\n",
            "[\"The Jeffersons\", \"Sitcom\"]\t[9, 1]\n",
            "[\"The Jim Gaffigan Show\", \"Sitcom\"]\t[3, 1]\n",
            "[\"The Josh Wolf Show\", \"Talk\", \"Comedy\"]\t[3, 2]\n",
            "[\"The King of Queens\", \"Sitcom\"]\t[146, 1]\n",
            "[\"The Late Late Show With James Corden\", \"Talk\", \"Comedy\"]\t[52, 2]\n",
            "[\"The Queen Latifah Show\", \"Talk\", \"Variety\"]\t[48, 2]\n",
            "[\"The Suite Life of Zack & Cody\", \"Children\", \"Sitcom\"]\t[11, 2]\n",
            "[\"The Tonight Show Starring Jimmy Fallon\", \"Talk\", \"Comedy\"]\t[9, 2]\n",
            "[\"Todo Lo Que T\\u00fa Quieras\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Town Square\", \"Community\"]\t[1, 1]\n",
            "[\"Un Balazo para Quintana\", \"Spanish\", \"Action\"]\t[1, 2]\n",
            "[\"Una Mujer Para los S\\u00e1bados\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Una Mujer Sin Amor\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Viaje Redondo\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"WLJC Spring Telethon\", \"Special\", \"Community\"]\t[1, 2]\n",
            "[\"What Would Julieanna Do?\", \"Talk\", \"Cooking\"]\t[1, 2]\n",
            "[\"Wizards of Waverly Place\", \"Children\", \"Sitcom\", \"Fantasy\"]\t[7, 3]\n",
            "[\"\\u00bfQui\\u00e9n Paga la Cuenta?\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"q\", \"Talk\", \"Entertainment\", \"Variety\"]\t[8, 3]\n",
            "[\"2014 LBJ Civil Rights Summit\", \"Community\"]\t[2, 1]\n",
            "[\"7 Cajas\", \"Spanish\", \"Action\", \"Suspense\"]\t[1, 3]\n",
            "[\"Adventures of Johnny Tao: Rock\", \"Action\", \"Adventure\", \"Martial arts\"]\t[1, 3]\n",
            "[\"Al Rojo Vivo\", \"Talk\", \"Newsmagazine\"]\t[4, 2]\n",
            "[\"Alicia Menendez Tonight\", \"Talk\", \"Politics\"]\t[1, 2]\n",
            "[\"Amor y Frijoles\", \"Spanish\", \"Comedy-drama\"]\t[2, 2]\n",
            "[\"Antiques Roadshow: In Bismarck\", \"Collectibles\", \"Community\"]\t[1, 2]\n",
            "[\"Aqu\\u00ed Nos Toc\\u00f3 Vivir\", \"Community\", \"Travel\"]\t[1, 2]\n",
            "[\"Around the Corner With John McGivern\", \"Community\"]\t[2, 1]\n",
            "[\"Arquitectos de lo Imposible\", \"Community\"]\t[1, 1]\n",
            "[\"Art Basel Design District Magazine\", \"Community\", \"Public affairs\"]\t[5, 2]\n",
            "[\"Bajo el Mismo Techo\", \"Sitcom\"]\t[1, 1]\n",
            "[\"Big Morning Buzz Live\", \"Talk\", \"Entertainment\", \"News\"]\t[2, 3]\n",
            "[\"Check Please! Arizona\", \"Community\"]\t[2, 1]\n",
            "[\"Choque de Opiniones\", \"Talk\", \"News\", \"Debate\"]\t[3, 3]\n",
            "[\"Cilantro y Perejil\", \"Spanish\", \"Romance-comedy\"]\t[1, 2]\n",
            "[\"Cool Jobs\", \"Community\", \"Educational\"]\t[8, 2]\n",
            "[\"Coruj\\u00e3o do Esporte\", \"Sports non-event\", \"Talk\"]\t[1, 2]\n",
            "[\"Crazy Talk\", \"Comedy\", \"Talk\"]\t[30, 2]\n",
            "[\"Crimenes De Lujuria\", \"Spanish\", \"Drama\", \"Suspense\"]\t[1, 3]\n",
            "[\"Di\\u00e1logos en Confianza\", \"Talk\"]\t[1, 1]\n",
            "[\"Dos Mojados En Apuros\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"Dulces Navajas\", \"Spanish\", \"Drama\"]\t[1, 2]\n",
            "[\"Duro y Parejo en la Casita del Pecado\", \"Spanish\", \"Comedy\"]\t[1, 2]\n",
            "[\"Ek The Raja Ek Thi Rani\", \"Community\"]\t[4, 1]\n",
            "[\"El Baile de San Juan\", \"Spanish\", \"Historical drama\"]\t[1, 2]\n",
            "[\"El Cuerpazo del Delito\", \"Spanish\", \"Comedy-drama\"]\t[1, 2]\n",
            "[\"El Efecto Tequila\", \"Spanish\", \"Comedy-drama\"]\t[1, 2]\n",
            "[\"El Esqueleto de la Se\\u00f1ora Morales\", \"Spanish\", \"Comedy-drama\"]\t[1, 2]\n",
            "Removing temp directory /tmp/hw1_mrA_337604821_326922390.root.20240710.125931.013212...\n"
          ]
        }
      ],
      "source": [
        "!python hw1_mrA_337604821_326922390.py 420k_daily_prog_data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7k0ljOqt7HL"
      },
      "source": [
        "------------------------------MarkDown --------------------------------------\n",
        "Part A Q1.B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAVK_IMruG3j",
        "outputId": "8b322553-67b0-453b-e847-1f1ec2206df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting hw1_mrB_337604821_326922390.py\n"
          ]
        }
      ],
      "source": [
        "%%file hw1_mrB_337604821_326922390.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import re\n",
        "\n",
        "def split_properley (line):\n",
        "    item = line.split(',')\n",
        "    date = item[-3]\n",
        "    air_time = int(item[-2]) if item[-2].isnumeric() else 0\n",
        "\n",
        "    if item[2] != item[-4]:\n",
        "        genres = line.split('\\\"')[1].split(',') if item[0] != 'title' else \"Hello World\"\n",
        "    else:\n",
        "      genres = [item[2]]\n",
        "    title = item[0].strip()\n",
        "    return title, genres, air_time, date\n",
        "\n",
        "class MRWordFrequencyCount(MRJob):\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper,\n",
        "                   reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_count_genres),\n",
        "            MRStep(reducer=self.reducer_max)\n",
        "        ]\n",
        "\n",
        "    def mapper(self, _, line): \n",
        "        title, genres, air_time, date = split_properley(line)\n",
        "        try:\n",
        "            if 70000 <= int(air_time) < 90000 and re.search('[jqz]', title.lower()):\n",
        "                for genre in genres:\n",
        "                    if genre.strip() in ['Sitcom', 'Talk', 'Politics', 'Spanish', 'Community', 'Martial arts']:\n",
        "                        ls = [title]\n",
        "                        ls.extend(genres)\n",
        "                        yield (tuple(ls), date)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    def reducer(self, key, dates):\n",
        "        unique_dates = set(dates)\n",
        "        yield key, len(unique_dates)\n",
        "\n",
        "    def reducer_count_genres(self, key, values):\n",
        "        total_dates = 0\n",
        "        for dates_count in values:\n",
        "            total_dates += dates_count\n",
        "        yield None, (key, total_dates + len(key)-1)# yield key with the sum of genres and total unique dates\n",
        "\n",
        "    def reducer_max(self, _, values):\n",
        "        yield max(values, key=lambda x: x[1])\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRWordFrequencyCount.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VkF1O2luqEQ",
        "outputId": "d2973db0-8934-4fb4-8222-70de0ba34cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/hw1_mrB_337604821_326922390.root.20240710.130008.257936\n",
            "Running step 1 of 3...\n",
            "Running step 2 of 3...\n",
            "Running step 3 of 3...\n",
            "job output is in /tmp/hw1_mrB_337604821_326922390.root.20240710.130008.257936/output\n",
            "Streaming final output from /tmp/hw1_mrB_337604821_326922390.root.20240710.130008.257936/output...\n",
            "[\"The King of Queens\", \"Sitcom\"]\t147\n",
            "Removing temp directory /tmp/hw1_mrB_337604821_326922390.root.20240710.130008.257936...\n"
          ]
        }
      ],
      "source": [
        "!python hw1_mrB_337604821_326922390.py 420k_daily_prog_data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwESOM18triT"
      },
      "source": [
        "------------------------------MarkDown --------------------------------------\n",
        "\n",
        "Part **B**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHxsvmaiYuRf"
      },
      "outputs": [],
      "source": [
        "# Install PySpark on the Colab machine - code in \"חומר עזר קולאב\"\n",
        "# Cell 1\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "# Cell 2\n",
        "!pip install --force-reinstall pyspark==3.4\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQT1QDboYzBb"
      },
      "outputs": [],
      "source": [
        "# Install PySpark on the Colab machine - code in \"חומר עזר קולאב\"\n",
        "# Cell 1\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "# Cell 2\n",
        "!pip install --force-reinstall pyspark==3.4\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9eBQPQiO3Bwx"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.mllib.random import RandomRDDs\n",
        "from pyspark.sql.types import*\n",
        "from pyspark.sql.functions import to_date, dayofweek, date_format\n",
        "import logging\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LKdLXo2lY0p6"
      },
      "outputs": [],
      "source": [
        "# Before getting/creating the Session, we can try to modify parameters.\n",
        "spark = SparkSession.builder.appName('Spark - HW01 Q2')\\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "# keep only important logs\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "kTO-We-DY_BA"
      },
      "outputs": [],
      "source": [
        "bl = [\"Big\", \"the\", \"bang\", \"theory\", \"almanac\", \"met\", \"mother\", \"your\", \"city\", \"anatomy\", \"game\", \"throne\", \"guy\", \"family\", \"friend\", \"senate\", \"two\"]\n",
        "\n",
        "g = lambda genre, typ, pnts: pnts if (typ in genre and len(genre) == 1) else 0 # give pnts based on matching genre if it's the only genre in tuple\n",
        "time_len = lambda time: time / 15\n",
        "def white_list(ls):\n",
        "  for word in bl:# check if given ls has a word in the black list, false if it does otherwise True.\n",
        "    for wrd in re.split('[,:]?\\s', ls):\n",
        "      if word.lower() == wrd.lower():\n",
        "        return False\n",
        "  return True\n",
        "# score calculation of tuple\n",
        "score_func = lambda title, genres, date, duration: (date + sum(g(genres, gg, p) for gg, p in zip([\"Action\", \"Documentary\", \"Sitcom\"],[90,90,7])) + time_len(duration)) if white_list(title) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "mApKkwbM1pJe"
      },
      "outputs": [],
      "source": [
        "def split_properly(item):\n",
        "  date = 3 if item[-3] and item[-3] in [1,3,5, 7] else 0 #looking for odd date\n",
        "  genres_tuple = tuple(item[2].split(',')) if item[2] else ()# find the different genres\n",
        "  title = item[0]\n",
        "  duration = float(str(item[-1])) if re.match(r\"^-?[0-9]+(\\.[0-9]+)?$\", str(item[-1])) else 0 # check if format matches and convert to float\n",
        "  return title, genres_tuple, date, duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "lwLadX971rYT"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('420k_daily_prog_data.csv', header=True, inferSchema=True)\n",
        "df = df.withColumn(\"air_date\", dayofweek(to_date(df.air_date, \"yyyyMMdd\")))# convert date to corresponding weekday value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "j_diZjes1tCi"
      },
      "outputs": [],
      "source": [
        "sol = df.rdd.map(split_properly) \\\n",
        "          .map(lambda row: ((row[0], row[1]), score_func(row[0], row[1], row[2], row[3]))) \\\n",
        "          .reduceByKey(lambda x, y: x + y) \\\n",
        "          .sortBy(lambda x: x[1], ascending=False)\n",
        "# rdd that applies split_properly on each row, then maps the title and genres to a score on each tuple\n",
        "# we then reduce to count duplicate keys to get total score and sort by to find the top ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cb6sjtOU1wEP"
      },
      "outputs": [],
      "source": [
        "solution = sol.collect()[:20]\n",
        "# run the action and take the top 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71VbcqRu2hSo",
        "outputId": "c73186f5-dd8d-42e1-d60c-9643c313e469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"SIGN OFF\", Special} | 22648.13333333333\n",
            "{\"Everybody Loves Raymond\", Sitcom} | 14961.533333333326\n",
            "{\"Documentary\", Documentary} | 13933.06666666666\n",
            "{\"Mike & Molly\", Sitcom} | 13269.600000000002\n",
            "{\"Hot in Cleveland\", Sitcom} | 11855.666666666668\n",
            "{\"Seinfeld\", Sitcom} | 11084.133333333335\n",
            "{\"Community\", Sitcom} | 9085.533333333333\n",
            "{\"ABC World News Now\", News} | 8337.999999999989\n",
            "{\"Strange Inheritance\", Documentary} | 8113.0\n",
            "{\"Un Mundo Maravilloso\", Documentary} | 8078.0\n",
            "{\"Drug Wars\", Documentary} | 7890.0\n",
            "{\"Weather Radar\", Weather} | 6987.0\n",
            "{\"True Life\", Documentary} | 5923.466666666664\n",
            "{\"Larry King Special Report\", Consumer} | 5796.4000000000015\n",
            "{\"Classic Arts Showcase\", Art} | 5731.666666666666\n",
            "{\"Programa Pagado\", Shopping} | 5447.799999999999\n",
            "{\"Live Cameras and Forecast Maps\", Weather} | 5391.733333333235\n",
            "{\"Forensic Files\", Reality, Crime} | 5277.0\n",
            "{\"Local Weather\", Weather} | 5257.0\n",
            "{\"Dateline on ID\", Documentary} | 5254.0\n"
          ]
        }
      ],
      "source": [
        "for (title, genres), score in solution:\n",
        "    genres_str = ', '.join(genres)\n",
        "    print(f'{{\"{title}\", {genres_str}}} | {score}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
